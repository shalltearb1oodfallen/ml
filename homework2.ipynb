{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5030f228-dc78-463f-8652-a28ebccbaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "df = pd.read_csv('homework2/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e163150-cef3-4394-b5cc-5ea0cd2b77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['ocean_proximity'].isin(['<1H OCEAN', 'INLAND'])]\n",
    "selected_columns = ['latitude', 'longitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n",
    "filtered_df = filtered_df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e27a4a-b5fd-4ac9-aba9-1edc200f47d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_bedrooms    157\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = filtered_df.isnull().sum()\n",
    "columns_with_missing_values = missing_values[missing_values > 0]\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de24448-a0fe-4730-b364-a20a2bcca0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median population: 1195.0\n"
     ]
    }
   ],
   "source": [
    "population_median = filtered_df['population'].median()\n",
    "print(\"Median population:\", population_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944b8270-7354-4928-927e-120f28cb4497",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = filtered_df.sample(frac=1, random_state=42)\n",
    "shuffled_df['median_house_value_log'] = np.log1p(shuffled_df['median_house_value'])\n",
    "# Split the data into train, val, and test sets (60%/20%/20%)\n",
    "train_df, temp_df = train_test_split(shuffled_df, test_size=0.4, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Calculate the mean of 'total_bedrooms' in train_df\n",
    "mean_total_bedrooms = train_df['total_bedrooms'].mean()\n",
    "\n",
    "# Fill missing values with the mean and create new variables\n",
    "train_df_filled = train_df.copy()\n",
    "train_df_filled['total_bedrooms'] = train_df_filled['total_bedrooms'].fillna(mean_total_bedrooms)\n",
    "\n",
    "val_df_filled = val_df.copy()\n",
    "val_df_filled['total_bedrooms'] = val_df_filled['total_bedrooms'].fillna(mean_total_bedrooms)\n",
    "\n",
    "test_df_filled = test_df.copy()\n",
    "test_df_filled['total_bedrooms'] = test_df_filled['total_bedrooms'].fillna(mean_total_bedrooms)\n",
    "\n",
    "# Create new variables with missing values replaced by 0\n",
    "train_df_zero_filled = train_df.fillna(0)\n",
    "val_df_zero_filled = val_df.fillna(0)\n",
    "test_df_zero_filled = test_df.fillna(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fdbdb2a-df7c-41f0-a267-5b256eede067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for val_df_filled predictions using total_bedrooms: 0.61\n"
     ]
    }
   ],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    error = np.abs((y_true - y_pred) / y_true)\n",
    "    mape_value = error.mean()\n",
    "    return mape_value\n",
    "\n",
    "X_train = train_df_filled[['total_bedrooms']]\n",
    "y_train = train_df_filled['median_house_value']\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_val = val_df_filled[['total_bedrooms']]\n",
    "y_val_true = val_df_filled['median_house_value']\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate MAPE for val_df_filled predictions\n",
    "mape_val = mape(y_val_true, y_val_pred)\n",
    "\n",
    "mape_val_rounded = round(mape_val, 2)\n",
    "\n",
    "print('MAPE for val_df_filled predictions using total_bedrooms:', mape_val_rounded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0235fb80-6fd3-4635-bf86-4ba3aa78803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for val_df_zero_filled predictions using total_bedrooms: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model using 'total_bedrooms' as the feature\n",
    "X_train_zero_filled = train_df_zero_filled[['total_bedrooms']]\n",
    "y_train_zero_filled = train_df_zero_filled['median_house_value']\n",
    "model_zero_filled = LinearRegression()\n",
    "model_zero_filled.fit(X_train_zero_filled, y_train_zero_filled)\n",
    "\n",
    "# Predict median_house_value for val_df_zero_filled\n",
    "X_val_zero_filled = val_df_zero_filled[['total_bedrooms']]\n",
    "y_val_true_zero_filled = val_df_zero_filled['median_house_value']\n",
    "y_val_pred_zero_filled = model_zero_filled.predict(X_val_zero_filled)\n",
    "\n",
    "# Calculate MAPE for val_df_zero_filled predictions\n",
    "mape_val_zero_filled = mape(y_val_true_zero_filled, y_val_pred_zero_filled)\n",
    "\n",
    "mape_val_zero_filled_rounded = round(mape_val_zero_filled, 2)\n",
    "\n",
    "print('MAPE for val_df_zero_filled predictions using total_bedrooms:', mape_val_zero_filled_rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89bdbf04-bec3-4f60-8909-eba56bcc2bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m w \u001b[38;5;241m=\u001b[39m train_linear_regression_reg(X_train, y_train, r\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Predict y for validation set\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate MAPE for validation predictions\u001b[39;00m\n\u001b[1;32m     32\u001b[0m mape_val \u001b[38;5;241m=\u001b[39m mape(y_val_true, y_val_pred)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def train_linear_regression_reg(X, y, r=0.0):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    reg = r * np.eye(XTX.shape[0])\n",
    "    XTX = XTX + reg\n",
    "\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    return w[0], w[1:]\n",
    "\n",
    "# List of regularization parameters\n",
    "r_values = [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "# Initialize variables to store the best MAPE and corresponding r\n",
    "best_mape = float('inf')  # Initialize with a large value\n",
    "best_r = None\n",
    "\n",
    "# Train models with different regularization parameters and calculate MAPE\n",
    "for r in r_values:\n",
    "    # Train a regularized linear regression model\n",
    "    w = train_linear_regression_reg(X_train, y_train, r=r)\n",
    "    \n",
    "    # Predict y for validation set\n",
    "    y_val_pred = np.dot(np.column_stack((np.ones(X_val.shape[0]), X_val)), w)\n",
    "    \n",
    "    # Calculate MAPE for validation predictions\n",
    "    mape_val = mape(y_val_true, y_val_pred)\n",
    "    \n",
    "    # Update best_mape and best_r if needed\n",
    "    if mape_val < best_mape:\n",
    "        best_mape = mape_val\n",
    "        best_r = r\n",
    "\n",
    "    print(f'MAPE for r = {r}: {round(mape_val, 6)}')\n",
    "\n",
    "print(f'\\nBest MAPE: {round(best_mape, 6)} for r = {best_r}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f41ed93b-4092-4829-baf6-5f3a7dfc2d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of MAPE scores: 0.004132\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    error = np.abs((y_true - y_pred) / y_true)\n",
    "    mape_value = np.mean(error)\n",
    "    return mape_value\n",
    "\n",
    "# Initialize an empty list to store MAPE scores\n",
    "mape_scores = []\n",
    "\n",
    "for seed in seed_values:\n",
    "    # Split the data into train, val, and test sets\n",
    "    shuffled_df = filtered_df.sample(frac=1, random_state=seed)\n",
    "    shuffled_df['median_house_value_log'] = np.log1p(shuffled_df['median_house_value'])\n",
    "\n",
    "    # Fill missing values with 0\n",
    "    shuffled_df_zero_filled = shuffled_df.fillna(0)\n",
    "\n",
    "    train_df, temp_df = train_test_split(shuffled_df_zero_filled, test_size=0.4, random_state=seed)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=seed)\n",
    "\n",
    "    # Train a model without regularization\n",
    "    X_train = train_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "    y_train = train_df['median_house_value_log']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on validation set\n",
    "    X_val = val_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "    y_val_true = val_df['median_house_value_log']\n",
    "\n",
    "    # Fill missing values with 0 for validation set\n",
    "    X_val_zero_filled = X_val.fillna(0)\n",
    "\n",
    "    y_val_pred = model.predict(X_val_zero_filled)\n",
    "\n",
    "    # Convert the predictions back to original scale\n",
    "    y_val_pred_original_scale = np.expm1(y_val_pred)\n",
    "    y_val_true_original_scale = np.expm1(y_val_true)\n",
    "\n",
    "    # Calculate MAPE for validation predictions\n",
    "    mape_val = mape(y_val_true_original_scale, y_val_pred_original_scale)\n",
    "    mape_scores.append(mape_val)\n",
    "\n",
    "    # Calculate the standard deviation of MAPE scores\n",
    "std_mape = np.std(mape_scores)\n",
    "\n",
    "# Round the standard deviation to 3 decimal places\n",
    "std_mape_rounded = round(std_mape, 6)\n",
    "\n",
    "print('Standard deviation of MAPE scores:', std_mape_rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b8476fa9-858f-4c58-bccf-2d44e0572c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>median_house_value_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>36.23</td>\n",
       "      <td>-119.14</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2935.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.5875</td>\n",
       "      <td>70400.0</td>\n",
       "      <td>11.161963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>34.12</td>\n",
       "      <td>-117.79</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>4.8125</td>\n",
       "      <td>224500.0</td>\n",
       "      <td>12.321635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>33.68</td>\n",
       "      <td>-117.97</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3653.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>5.7301</td>\n",
       "      <td>260900.0</td>\n",
       "      <td>12.471896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>34.10</td>\n",
       "      <td>-118.03</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>2.9422</td>\n",
       "      <td>233100.0</td>\n",
       "      <td>12.359227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17546</th>\n",
       "      <td>37.34</td>\n",
       "      <td>-121.87</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2479.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>2.4306</td>\n",
       "      <td>289100.0</td>\n",
       "      <td>12.574531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6651</th>\n",
       "      <td>34.15</td>\n",
       "      <td>-118.14</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1.9923</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>13.122367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17810</th>\n",
       "      <td>37.40</td>\n",
       "      <td>-121.86</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4043.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>2196.0</td>\n",
       "      <td>708.0</td>\n",
       "      <td>6.1504</td>\n",
       "      <td>268400.0</td>\n",
       "      <td>12.500237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>34.07</td>\n",
       "      <td>-118.15</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>3.2875</td>\n",
       "      <td>234400.0</td>\n",
       "      <td>12.364789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>36.78</td>\n",
       "      <td>-119.81</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>3.6250</td>\n",
       "      <td>83400.0</td>\n",
       "      <td>11.331416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>34.00</td>\n",
       "      <td>-118.35</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3402.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>5.3462</td>\n",
       "      <td>270400.0</td>\n",
       "      <td>12.507661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15687 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "19963     36.23    -119.14                22.0       2935.0           523.0   \n",
       "5929      34.12    -117.79                16.0       2426.0           426.0   \n",
       "11377     33.68    -117.97                26.0       3653.0           568.0   \n",
       "6443      34.10    -118.03                32.0       2668.0           609.0   \n",
       "17546     37.34    -121.87                39.0       2479.0           541.0   \n",
       "...         ...        ...                 ...          ...             ...   \n",
       "6651      34.15    -118.14                41.0       1256.0           407.0   \n",
       "17810     37.40    -121.86                19.0       4043.0           764.0   \n",
       "6850      34.07    -118.15                52.0       1983.0           344.0   \n",
       "2161      36.78    -119.81                37.0       1965.0           364.0   \n",
       "8992      34.00    -118.35                46.0       3402.0           503.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "19963      1927.0       530.0         2.5875             70400.0   \n",
       "5929       1319.0       446.0         4.8125            224500.0   \n",
       "11377      1930.0       585.0         5.7301            260900.0   \n",
       "6443       1512.0       541.0         2.9422            233100.0   \n",
       "17546      1990.0       506.0         2.4306            289100.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "6651        855.0       383.0         1.9923            500001.0   \n",
       "17810      2196.0       708.0         6.1504            268400.0   \n",
       "6850        887.0       331.0         3.2875            234400.0   \n",
       "2161        796.0       335.0         3.6250             83400.0   \n",
       "8992       1389.0       504.0         5.3462            270400.0   \n",
       "\n",
       "       median_house_value_log  \n",
       "19963               11.161963  \n",
       "5929                12.321635  \n",
       "11377               12.471896  \n",
       "6443                12.359227  \n",
       "17546               12.574531  \n",
       "...                       ...  \n",
       "6651                13.122367  \n",
       "17810               12.500237  \n",
       "6850                12.364789  \n",
       "2161                11.331416  \n",
       "8992                12.507661  \n",
       "\n",
       "[15687 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afbf14b0-d72d-455c-866f-176a8614d2ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3138,8) and (1,8) not aligned: 8 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m X_test_zero_filled \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Predictions on the test set\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_zero_filled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Convert the predictions back to original scale\u001b[39;00m\n\u001b[1;32m     35\u001b[0m y_test_pred_original_scale \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test_pred)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3138,8) and (1,8) not aligned: 8 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 9\n",
    "\n",
    "# Split the data into train, val, and test sets\n",
    "shuffled_df = filtered_df.sample(frac=1, random_state=seed)\n",
    "shuffled_df['median_house_value_log'] = np.log1p(shuffled_df['median_house_value'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "shuffled_df_zero_filled = shuffled_df.fillna(0)\n",
    "\n",
    "train_df, temp_df = train_test_split(shuffled_df_zero_filled, test_size=0.4, random_state=seed)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=seed)\n",
    "\n",
    "# Combine train and validation datasets\n",
    "train_val_df = pd.concat([train_df, val_df])\n",
    "\n",
    "# Train a model without regularization\n",
    "X_train_val = train_val_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "y_train_val = train_val_df['median_house_value_log']\n",
    "model = train_linear_regression_reg(X_train_val, y_train_val, r=0.001)\n",
    "\n",
    "# Predict on test set\n",
    "X_test = test_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "y_test_true = test_df['median_house_value_log']\n",
    "\n",
    "# Fill missing values with 0 for test set\n",
    "X_test_zero_filled = X_test.fillna(0)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = model[0] + np.dot(X_test_zero_filled, model[1:])\n",
    "\n",
    "# Convert the predictions back to original scale\n",
    "y_test_pred_original_scale = np.expm1(y_test_pred)\n",
    "y_test_true_original_scale = np.expm1(y_test_true)\n",
    "\n",
    "# Calculate RMSE for test predictions\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_true_original_scale, y_test_pred_original_scale))\n",
    "\n",
    "print('RMSE on the test dataset:', round(rmse_test, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b37415d-c019-42bd-a63c-9c7ec4ac94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the test dataset: 83593.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "seed = 9\n",
    "\n",
    "# Split the data into train, val, and test sets\n",
    "shuffled_df = filtered_df.sample(frac=1, random_state=seed)\n",
    "shuffled_df['median_house_value_log'] = np.log1p(shuffled_df['median_house_value'])\n",
    "\n",
    "# Fill missing values with 0\n",
    "shuffled_df_zero_filled = shuffled_df.fillna(0)\n",
    "\n",
    "train_df, temp_df = train_test_split(shuffled_df_zero_filled, test_size=0.4, random_state=seed)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=seed)\n",
    "\n",
    "# Combine train and validation datasets\n",
    "train_val_df = pd.concat([train_df, val_df])\n",
    "\n",
    "# Train a model without regularization\n",
    "X_train_val = train_val_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "y_train_val = train_val_df['median_house_value_log']\n",
    "intercept, weights = train_linear_regression_reg(X_train_val, y_train_val, r=0.001)\n",
    "\n",
    "# Predict on test set\n",
    "X_test = test_df.drop(['median_house_value', 'median_house_value_log'], axis=1)\n",
    "\n",
    "# Fill missing values with 0 for test set\n",
    "X_test_zero_filled = X_test.fillna(0)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = intercept + np.dot(X_test_zero_filled, weights)\n",
    "\n",
    "# Convert the predictions back to original scale\n",
    "y_test_pred_original_scale = np.expm1(y_test_pred)\n",
    "y_test_true_original_scale = np.expm1(test_df['median_house_value_log'])\n",
    "\n",
    "# Calculate RMSE for test predictions\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test_true_original_scale, y_test_pred_original_scale))\n",
    "\n",
    "print('RMSE on the test dataset:', round(rmse_test, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74ce0b2a-f53a-4035-af5b-bfdc2f3259f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE on the test dataset: 0.263\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mape(y_true, y_pred):\n",
    "    error = np.abs((y_true - y_pred) / y_true)\n",
    "    mape_value = np.mean(error)\n",
    "    return mape_value\n",
    "\n",
    "# Calculate MAPE for test predictions\n",
    "mape_test = mape(y_test_true_original_scale, y_test_pred_original_scale)\n",
    "\n",
    "print('MAPE on the test dataset:', round(mape_test, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a70f0-f12d-4f77-99a0-6d8d56a6ca8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
